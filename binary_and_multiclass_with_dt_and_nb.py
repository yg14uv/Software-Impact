# -*- coding: utf-8 -*-
"""Binary and Multiclass with DT and NB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MNJEzK_il38XJg0ShCdjHvE08BPCC003

**Part A** is for Binary classification

> Indented block


**Part B** is for multiclassification
"""



"""Importing Dataset from google drive

"""

import pandas as pd

import numpy
from sklearn import preprocessing
from sklearn.naive_bayes import GaussianNB
from sklearn import metrics
import ipaddress
from sklearn.model_selection import train_test_split
from sklearn import tree
from matplotlib import pyplot as plt

#dataframe=pd.read_csv("/content/drive/MyDrive/IoTID20/IoT Intrusion Dataset 2020.csv")
dataframe = pd.read_csv('IoTID20.csv')
print(dataframe)

"""Visulizing Data Set:"""

dataframe.head(10)

"""Describing Dataset:"""

dataframe.describe()

"""
Defining input and target columns for Part A:

"""

inputA = dataframe.drop('Label', axis = 'columns')
print(inputA.head())
target_ColA = dataframe['Label']
print(target_ColA.head())

"""Defining input and target columns for PartB:

"""

inputB = dataframe.drop('Sub_Cat', axis = 'columns')
print(inputB.head())
target_ColB = dataframe['Sub_Cat']
print(target_ColB.head())

"""DataPreporcessing Part A:"""

from sklearn.preprocessing import LabelEncoder
label_inputA = LabelEncoder()
inputA = inputA.apply(label_inputA.fit_transform)
print(inputA.head())

"""DataPreporcessing PartB:"""

label_inputPartB = LabelEncoder()
inputB = inputB.apply(label_inputPartB.fit_transform)
print(inputB.head())

"""Splitting the dataset into test and train columns Part A: """

from sklearn.model_selection import train_test_split

X_trainA, X_testA, y_trainA, y_testA = train_test_split(inputA, target_ColA, test_size=0.2)

"""Aplying Decision Tree Classification Part A:"""

from sklearn.tree import DecisionTreeClassifier
modelPartA = DecisionTreeClassifier()
modelPartA.fit(X_trainA, y_trainA)

"""Accuracy of the model Part A:"""

from sklearn.metrics import accuracy_score
accuracyPartA = modelPartA.score(X_testA, y_testA)*100
print("Accuracy of Part A model = ", accuracyPartA, "%")

"""spliting test and train data PartB:"""

X_trainB, X_testB, y_trainB, y_testB = train_test_split(inputB, target_ColB, test_size=0.3)

"""Aplying Decision tree classification Part B:"""

modelPartB = DecisionTreeClassifier()
modelPartB.fit(X_trainB, y_trainB)

"""Accuracy of model PartB:"""

accuracyPartB = modelPartB.score(X_testB, y_testB)*100
print("Accuracy of Part B model = ", accuracyPartB, "%")

"""Applying Naive bayes classification Part A:"""

from sklearn.naive_bayes import GaussianNB
modelA_NB = GaussianNB()
modelA_NB.fit(X_trainA, y_trainA);

"""Accuray of Naive baye Part A:"""

accuracyPartA_NB = modelA_NB.score(X_testA, y_testA)*100
print("Accuracy of Part A model = ", accuracyPartA_NB, "%")

"""Applying naive_bayes classification on Part B:"""

modelB_NB = GaussianNB()
modelB_NB.fit(X_trainB, y_trainB);

"""Accuracy of Naive Bayes model Part B:"""

accuracyPartB_NB = modelB_NB.score(X_testB, y_testB)*100
print("Accuracy of Part B model = ", accuracyPartB_NB, "%")

"""Single class classification:
Part A:

1-Accuracy
"""

Y_predA=modelPartA.predict(X_testA)
print("Accuracy of Part A model after aplying decision tree:   ",metrics.accuracy_score(y_testA, Y_predA)*100 ,"%")
Y_predB=modelPartB.predict(X_testB)
print("Accuracy of Part B model after aplying decision tree:   ",metrics.accuracy_score(y_testB, Y_predB)*100 ,"%")
y_predA_nb=modelA_NB.predict(X_testA)
print("Accuracy of Part A model after aplying Naive bayes :   ",metrics.accuracy_score(y_testA, y_predA_nb)*100 ,"%")
y_predB_nb=modelB_NB.predict(X_testB)
print("Accuracy of Part B model after aplying Naive bayes :   ",metrics.accuracy_score(y_testB, y_predB_nb)*100 ,"%")

"""2-Precision"""

prec_A = metrics.precision_score(y_testA, Y_predA,average='micro')
print("Precision for part A model after applying decision tree:",prec_A)
prec_B = metrics.precision_score(y_testB, Y_predB,average='micro')
print("Precision for part B model after applying decision tree:",prec_B)
prec_PartA_nb=metrics.precision_score(y_testA, y_predA_nb,average='micro')
print("Precision for Part A model after aplying Naive bayes:   " ,prec_PartA_nb)
prec_PartB_nb=metrics.precision_score(y_testB, y_predB_nb,average='micro')
print("Precision for Part B model after aplying Naive bayes:   " ,prec_PartB_nb)

"""3-Recall"""

recall_partA = metrics.recall_score(y_testA, Y_predA,average='micro')
print("Recall score for model Part A after applying decison tree:",recall_partA)
recall_partB = metrics.recall_score(y_testB, Y_predB,average='micro')
print("Recall score  model Part B after applying decison tree:",recall_partB)
recall_PartA_nb=metrics.recall_score(y_testA, y_predA_nb,average='micro')
print(" Recall score Part A model after aplying Naive bayes:   " ,recall_PartA_nb)
recall_PartB_nb=metrics.recall_score(y_testB, y_predB_nb,average='micro')
print(" Recall score for Part B model after aplying Naive bayes:   " ,recall_PartB_nb)

"""F1 Score(F Measure)
The F measure can be claculated using the formula F-Measure = (2 * Precision * Recall) / (Precision + Recall)
"""

Fmeasure_PartA=(2*prec_A*recall_partA)/(prec_A+recall_partA)
print("The F measure for model part A after applying decision tree:  ",Fmeasure_PartA)
Fmeasure_PartB=(2*prec_B*recall_partB)/(prec_B+recall_partB)
print("The F measure for model part B after applying decision tree:  ",Fmeasure_PartB)
Fmeasure_PartA_nb=(2*prec_PartA_nb*recall_PartA_nb)/(prec_PartA_nb+recall_PartA_nb)
print("The F measure for model part A after applying Naive bayes:  ",Fmeasure_PartA_nb)
Fmeasure_PartB_nb=(2*prec_PartB_nb*recall_PartB_nb)/(prec_PartB_nb+recall_PartB_nb)
print("The F measure for model part B after applying Naive bayes:  ",Fmeasure_PartB_nb)

"""Part A model:

Confusion Matrix

Confusion Matrix for descison tree
"""

import seaborn as sn
df_cm = pd.DataFrame(metrics.confusion_matrix(y_testA, Y_predA), range(2), range(2))
sn.set(font_scale=1) 
sn.heatmap(df_cm, annot=True, annot_kws={"size": 10}) # font size
plt.show()

"""Confusion Matrix for  Naive bayes classification"""

import seaborn as sn
df_cm = pd.DataFrame(metrics.confusion_matrix(y_testA, y_predA_nb), range(2), range(2))
sn.set(font_scale=1) 
sn.heatmap(df_cm, annot=True, annot_kws={"size": 10}) # font size
plt.show()

"""True Positive Rate (Sensitivity)

True Positive rate can be calculated as Rate = TP/TP+FN Where TP = Total true positives FN = Total False Negatives

---

For Decision Tree:
"""

tn_dt,fp_dt,fn_dt,tp_dt = metrics.confusion_matrix(y_testA, Y_predA).ravel()
print("True Positive rate for Decision trees is: ", tp_dt/(tp_dt+fn_dt))

"""For Naive bayes:"""

tn_nb,fp_nb,fn_nb,tp_nb = metrics.confusion_matrix(y_testA, y_predA_nb).ravel()
print("True Positive rate for naive bayes is: ", tp_nb/(tp_nb+fn_nb))

"""False Positive Rate (Specificity)


---







False Positive rate can be calculated as False Positive Rate = FP/FP+TN Where FP = Total False positives TN = Total True Negatives

For Decision tree:
"""

tn_dt,fp_dt,fn_dt,tp_dt = metrics.confusion_matrix(y_testA, Y_predA).ravel()
print("False Positive rate for Decision trees is: ", fp_dt/(fp_dt+tn_dt))

"""For Naive bayes:"""

tn_nb,fp_nb,fn_nb,tp_nb = metrics.confusion_matrix(y_testA, y_predA_nb).ravel()
print("False Positive rate for naive bayes is: ", fp_nb/(fp_nb+tn_nb))

"""Classification Report:

For Decision Tree:
"""

print(metrics.classification_report(y_testA, Y_predA, labels=['Normal','Anomaly']))

"""For Naive Bayes:"""

print(metrics.classification_report(y_testA, y_predA_nb, labels=['Normal','Anomaly']))

"""Multi class classification:

---
Part B:

Confusion matrix:

---

For Decision Tree:
"""

import seaborn as sn
df_cm = pd.DataFrame(metrics.confusion_matrix(y_testB, Y_predB), range(9), range(9))
sn.set(font_scale=1.4) 
sn.heatmap(df_cm, annot=True, annot_kws={"size": 7}) # font size
plt.show()

"""For Naive bayes:"""

import seaborn as sn
df_cm = pd.DataFrame(metrics.confusion_matrix(y_testB, y_predB_nb), range(9), range(9))
sn.set(font_scale=1.4) 
sn.heatmap(df_cm, annot=True, annot_kws={"size": 7}) # font size
plt.show()

"""True Positive Rate (Sensitivity)

True Positive rate can be calculated as Rate = TP/TP+FN Where TP = Total true positives FN = Total False Negatives

For Decision Tree:
"""

cnf_matrix = metrics.confusion_matrix(y_testB, Y_predB)

fp_dt = cnf_matrix.sum(axis=0) - numpy.diag(cnf_matrix)  
fn_dt = cnf_matrix.sum(axis=1) - numpy.diag(cnf_matrix)
tp_dt = numpy.diag(cnf_matrix)
tn_dt = cnf_matrix.sum() - (fp_dt + fp_dt + fp_dt)

fp_dt = fp_dt.astype(float)
fn_dt = fn_dt.astype(float)
tp_dt = tp_dt.astype(float)
tn_dt = tn_dt.astype(float)

TPR_dt = tp_dt/(tp_dt+fn_dt)
tpr_dt =0
for i in TPR_dt:
  tpr_dt +=i
tpr_dt = tpr_dt/len(TPR_dt)   
print("True Positive rate for naive bayes is: ", tpr_dt)

"""For Naive bayes:"""

cnf_matrix = metrics.confusion_matrix(y_testB, y_predB_nb)

fp_nb = cnf_matrix.sum(axis=0) - numpy.diag(cnf_matrix)  
fn_nb = cnf_matrix.sum(axis=1) - numpy.diag(cnf_matrix)
tp_nb = numpy.diag(cnf_matrix)
tn_nb = cnf_matrix.sum() - (fp_nb + fp_nb + fp_nb)

fp_nb = fp_nb.astype(float)
fn_nb = fn_nb.astype(float)
tp_nb = tp_nb.astype(float)
tn_nb = tn_nb.astype(float)

TPR_nb = tp_nb/(tp_nb+fn_nb)
tpr_nb =0
for i in TPR_nb:
  tpr_nb +=i
tpr_nb = tpr_nb/len(TPR_nb)   
print("True Positive rate for naive bayes is: ", tpr_nb)

"""False Positive Rate (Specificity)

False Positive rate can be calculated as False Positive Rate = FP/FP+TN Where FP = Total False positives TN = Total True Negatives

For Decision Tree:
"""

FPR_dt = fp_dt/(fp_dt+tn_dt)
fpr_dt =0
for i in FPR_dt:
  fpr_dt +=i
fpr_dt = fpr_dt/len(FPR_dt)
print("False Positive rate for naive bayes is: ", fpr_dt)

"""For Naive bayes:"""

FPR_nb = fp_nb/(fp_nb+tn_nb)
fpr_nb =0
for i in FPR_nb:
  fpr_nb +=i
fpr_nb = fpr_nb/len(FPR_nb)
print("False Positive rate for naive bayes is: ", fpr_nb)

"""ROC Curves:

For Decision Tree:
"""

plt.plot(FPR_dt,TPR_dt, color='orange', label='ROC')
plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Decision Trees')
plt.legend()
plt.show()

"""For Naive Bayes:"""

plt.plot(FPR_nb,TPR_nb, color='orange', label='ROC')
plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Naive Bayes')
plt.legend()
plt.show()

"""Classification Report:

For decision Tree:
"""

print(metrics.classification_report(y_testB, Y_predB, labels=['Mirai-Ackflooding','DoS-Synflooding','Scan Port OS','Mirai-Hostbruteforceg','Mirai-UDP Flooding','Mirai-HTTP Flooding','Normal','Scan Hostport','MITM ARP Spoofing']))

"""For Naive bayes:"""

print(metrics.classification_report(y_testB, y_predB_nb, labels=['Mirai-Ackflooding','DoS-Synflooding','Scan Port OS','Mirai-Hostbruteforceg','Mirai-UDP Flooding','Mirai-HTTP Flooding','Normal','Scan Hostport','MITM ARP Spoofing']))